#!/usr/bin/env python3
"""
AI Content Generator with Intent Analysis and Context Management

This script uses OpenAI's API to generate content based on user input.
It analyzes user intent, maintains context history, and generates responses.

Usage:
    python content_generator.py "Your question or prompt here"
"""

import os
import re
import argparse
from datetime import datetime
from typing import List, Optional, Tuple
from dotenv import load_dotenv
from openai import OpenAI


class OpenAIClient:
    """Wrapper class for OpenAI API interactions"""

    def __init__(self, api_key: str, base_url: Optional[str] = None):
        """Initialize OpenAI client with optional custom base_url"""
        if base_url:
            self.client = OpenAI(api_key=api_key, base_url=base_url)
        else:
            self.client = OpenAI(api_key=api_key)

    def chat_completion(self, messages: List[dict], model: str = "gpt-3.5-turbo") -> str:
        """Send chat completion request to OpenAI"""
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
                max_tokens=1024*16
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            raise Exception(f"OpenAI API call failed: {str(e)}")


class ContextManager:
    """Manages context storage and retrieval from user_context.md"""

    def __init__(self, context_file: str = "user_context.md"):
        self.context_file = context_file
        self._ensure_context_file_exists()

    def _ensure_context_file_exists(self):
        """Create context file if it doesn't exist"""
        if not os.path.exists(self.context_file):
            with open(self.context_file, 'w', encoding='utf-8') as f:
                f.write("# User Context History\n\n")

    def add_context(self, intent: str) -> int:
        """Add new intent to context file with sequential numbering"""
        try:
            # Read existing content
            with open(self.context_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # Find the highest existing number
            numbers = re.findall(r'^# (\d+)$', content, re.MULTILINE)
            next_number = max([int(n) for n in numbers] + [0]) + 1

            # Append new context
            with open(self.context_file, 'a', encoding='utf-8') as f:
                f.write(f"# {next_number}\n{intent}\n\n")

            return next_number
        except Exception as e:
            raise Exception(f"Failed to add context: {str(e)}")

    def get_latest_contexts(self, count: int = 3) -> List[str]:
        """Get the latest 'count' contexts from the file"""
        try:
            with open(self.context_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # Find all context entries
            pattern = r'^# (\d+)\n(.*?)(?=\n# |\Z)'
            matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)

            # Sort by number and get latest
            matches.sort(key=lambda x: int(x[0]))
            latest_matches = matches[-count:] if len(matches) >= count else matches

            # Extract just the intent content
            return [match[1].strip() for match in latest_matches]
        except Exception as e:
            raise Exception(f"Failed to get contexts: {str(e)}")


def parse_user_intent(openai_client: OpenAIClient, user_input: str, model: str) -> str:
    """Parse user intent using AI with thinking capability"""
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ„å›¾åˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œå‡†ç¡®è¯†åˆ«å¹¶æå–ç”¨æˆ·çš„æ ¸å¿ƒæ„å›¾å’Œéœ€æ±‚ã€‚

åˆ†æè¦æ±‚ï¼š
1. è¯†åˆ«ç”¨æˆ·æƒ³è¦å®Œæˆçš„å…·ä½“ä»»åŠ¡
2. æå–å…³é”®ä¿¡æ¯å’Œéœ€æ±‚ç‚¹
3. ç®€æ´æ˜ç¡®åœ°æè¿°ç”¨æˆ·æ„å›¾
4. ä¿æŒåŸæ„çš„å®Œæ•´æ€§

é‡è¦ï¼šè¯·ç›´æ¥è¿”å›ç”¨æˆ·æ„å›¾çš„æè¿°ï¼Œä¸è¦åŒ…å«"ç”¨æˆ·æ„å›¾ï¼š"ã€"åˆ†æç»“æœï¼š"ç­‰ä»»ä½•å‰ç¼€ï¼Œåªéœ€è¿”å›çº¯å‡€çš„æ„å›¾å†…å®¹ã€‚"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"ç”¨æˆ·è¾“å…¥ï¼š{user_input}"}
    ]

    intent = openai_client.chat_completion(messages, model)

    # æ¸…ç†å¯èƒ½çš„æ ¼å¼åŒ–å‰ç¼€
    intent = intent.strip()
    if intent.startswith("ç”¨æˆ·æ„å›¾ï¼š"):
        intent = intent[5:].strip()
    elif intent.startswith("ç”¨æˆ·æ„å›¾:"):
        intent = intent[4:].strip()
    elif intent.startswith("åˆ†æç»“æœï¼š"):
        intent = intent[5:].strip()
    elif intent.startswith("åˆ†æç»“æœ:"):
        intent = intent[4:].strip()

    return intent


def generate_final_content(openai_client: OpenAIClient, user_input: str, contexts: List[str], system_prompt: str, model: str) -> str:
    """Generate final content based on user input, context, and system prompt"""
    context_text = "\n".join([f"ä¸Šä¸‹æ–‡ {i+1}: {ctx}" for i, ctx in enumerate(contexts)])
    context_text = context_text if context_text else "æš‚æ— ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"

    full_prompt = f"""ç³»ç»Ÿè¦æ±‚ï¼š{system_prompt}

ç”¨æˆ·è¾“å…¥ï¼š{user_input}

å†å²ä¸Šä¸‹æ–‡ï¼š
{context_text}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç”Ÿæˆåˆé€‚çš„å†…å®¹å›å¤ã€‚"""

    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹ç”ŸæˆåŠ©æ‰‹ï¼Œå–„äºæ ¹æ®ç³»ç»Ÿè¦æ±‚ã€ç”¨æˆ·è¾“å…¥å’Œå†å²ä¸Šä¸‹æ–‡ç”Ÿæˆé«˜è´¨é‡çš„å›å¤ã€‚"},
        {"role": "user", "content": full_prompt}
    ]

    return openai_client.chat_completion(messages, model)


def generate_inspirational_quote(openai_client: OpenAIClient, model: str) -> dict:
    """Generate a random inspirational quote with detailed analysis"""

    # Step 1: Generate the quote
    quote_prompt = """è¯·ç”Ÿæˆä¸€å¥å¯Œæœ‰å“²ç†å’Œå¯å‘æ€§çš„åŠ±å¿—åè¨€ã€‚è¦æ±‚ï¼š
1. å†…å®¹ç§¯æå‘ä¸Šï¼Œå…·æœ‰æ·±åº¦æ€è€ƒä»·å€¼
2. è¯­è¨€ç®€æ´ä¼˜ç¾ï¼Œæ˜“äºè®°å¿†å’Œä¼ æ’­
3. æ¶µç›–äººç”Ÿã€æˆåŠŸã€æˆé•¿ã€æ™ºæ…§ç­‰ä¸»é¢˜
4. é¿å…è¿‡äºå¸¸è§æˆ–é™ˆè¯æ»¥è°ƒçš„å†…å®¹
5. æä¾›ä¸€ä¸ªè™šæ„ä½†åˆç†çš„ä½œè€…å§“åå’ŒèƒŒæ™¯

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{
    "quote": "åè¨€å†…å®¹",
    "author": "ä½œè€…å§“å",
    "background": "ä½œè€…èƒŒæ™¯ç®€ä»‹"
}"""

    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åè¨€åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ›ä½œå¯Œæœ‰å“²ç†å’Œå¯å‘æ€§çš„åè¨€è­¦å¥ã€‚"},
        {"role": "user", "content": quote_prompt}
    ]

    try:
        quote_response = openai_client.chat_completion(messages, model)

        # Parse JSON response - handle markdown code blocks
        import json
        import re

        # Extract JSON from response (handle markdown code blocks)
        json_match = re.search(r'```json\s*\n(.*?)\n```', quote_response, re.DOTALL)
        if json_match:
            json_text = json_match.group(1)
        else:
            # Try to find JSON object directly
            json_match = re.search(r'\{.*\}', quote_response, re.DOTALL)
            if json_match:
                json_text = json_match.group(0)
            else:
                json_text = quote_response

        quote_data = json.loads(json_text)

        # Validate required fields
        if not all(key in quote_data for key in ['quote', 'author', 'background']):
            raise ValueError("Missing required fields in quote data")

        # Step 2: Generate detailed analysis
        analysis_prompt = f"""è¯·å¯¹ä»¥ä¸‹åè¨€è¿›è¡Œæ·±åº¦åˆ†æï¼š

åè¨€ï¼š"{quote_data['quote']}"
ä½œè€…ï¼š{quote_data['author']}
ä½œè€…èƒŒæ™¯ï¼š{quote_data['background']}

è¯·æä¾›è¯¦ç»†çš„åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. **åè¨€è§£è¯»**ï¼šè§£é‡Šè¿™å¥åè¨€çš„æ·±å±‚å«ä¹‰å’Œå“²å­¦æ€æƒ³
2. **å†å²èƒŒæ™¯**ï¼šåˆ†æè¿™å¥åè¨€äº§ç”Ÿçš„å†å²æ—¶ä»£èƒŒæ™¯å’Œç¤¾ä¼šç¯å¢ƒ
3. **ç°å®æ„ä¹‰**ï¼šæ¢è®¨è¿™å¥åè¨€åœ¨å½“ä»£ç¤¾ä¼šçš„åº”ç”¨ä»·å€¼å’ŒæŒ‡å¯¼æ„ä¹‰
4. **ç›¸å…³å¼•ç”¨**ï¼šæä¾›2-3ä¸ªå†å²ä¸Šæˆ–å½“ä»£åäººå¼•ç”¨ç±»ä¼¼æ€æƒ³çš„ä¾‹å­
5. **å®è·µå»ºè®®**ï¼šç»™å‡ºå¦‚ä½•åœ¨ç”Ÿæ´»ä¸­è·µè¡Œè¿™å¥åè¨€çš„å…·ä½“å»ºè®®

è¯·ä¿æŒåˆ†æçš„ä¸“ä¸šæ€§å’Œæ·±åº¦ï¼Œè¯­è¨€ä¼˜ç¾æµç•…ï¼Œå­—æ•°æ§åˆ¶åœ¨800-1200å­—ä¹‹é—´ã€‚"""

        analysis_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ€æƒ³å­¦è€…å’Œæ–‡å­¦è¯„è®ºå®¶ï¼Œæ“…é•¿å¯¹åè¨€è­¦å¥è¿›è¡Œæ·±åº¦è§£è¯»å’Œåˆ†æã€‚"},
            {"role": "user", "content": analysis_prompt}
        ]

        analysis = openai_client.chat_completion(analysis_messages, model)

        return {
            'quote': quote_data['quote'],
            'author': quote_data['author'],
            'background': quote_data['background'],
            'analysis': analysis
        }

    except (json.JSONDecodeError, ValueError, KeyError) as e:
        # Fallback with detailed analysis
        fallback_quote = "æˆåŠŸä¸æ˜¯ç»ˆç‚¹ï¼Œå¤±è´¥ä¸æ˜¯ç»ˆç»“ï¼Œå”¯æœ‰å‹‡æ°”æ‰æ˜¯æ°¸æ’ã€‚"
        fallback_author = "æ¸©æ–¯é¡¿Â·ä¸˜å‰å°”"
        fallback_background = "è‹±å›½é¦–ç›¸ï¼ŒäºŒæˆ˜æ—¶æœŸé¢†å¯¼äººç‰©ï¼Œä»¥åšéŸ§ä¸æ‹”çš„æ„å¿—å’Œå“è¶Šçš„é¢†å¯¼æ‰èƒ½è‘—ç§°ã€‚"

        # Generate analysis for fallback quote
        analysis_prompt = f"""è¯·å¯¹ä»¥ä¸‹åè¨€è¿›è¡Œæ·±åº¦åˆ†æï¼š

åè¨€ï¼š"{fallback_quote}"
ä½œè€…ï¼š{fallback_author}
ä½œè€…èƒŒæ™¯ï¼š{fallback_background}

è¯·æä¾›è¯¦ç»†çš„åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. **åè¨€è§£è¯»**ï¼šè§£é‡Šè¿™å¥åè¨€çš„æ·±å±‚å«ä¹‰å’Œå“²å­¦æ€æƒ³
2. **å†å²èƒŒæ™¯**ï¼šåˆ†æè¿™å¥åè¨€äº§ç”Ÿçš„å†å²æ—¶ä»£èƒŒæ™¯å’Œç¤¾ä¼šç¯å¢ƒ
3. **ç°å®æ„ä¹‰**ï¼šæ¢è®¨è¿™å¥åè¨€åœ¨å½“ä»£ç¤¾ä¼šçš„åº”ç”¨ä»·å€¼å’ŒæŒ‡å¯¼æ„ä¹‰
4. **ç›¸å…³å¼•ç”¨**ï¼šæä¾›2-3ä¸ªå†å²ä¸Šæˆ–å½“ä»£åäººå¼•ç”¨ç±»ä¼¼æ€æƒ³çš„ä¾‹å­
5. **å®è·µå»ºè®®**ï¼šç»™å‡ºå¦‚ä½•åœ¨ç”Ÿæ´»ä¸­è·µè¡Œè¿™å¥åè¨€çš„å…·ä½“å»ºè®®

è¯·ä¿æŒåˆ†æçš„ä¸“ä¸šæ€§å’Œæ·±åº¦ï¼Œè¯­è¨€ä¼˜ç¾æµç•…ï¼Œå­—æ•°æ§åˆ¶åœ¨800-1200å­—ä¹‹é—´ã€‚"""

        analysis_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ€æƒ³å­¦è€…å’Œæ–‡å­¦è¯„è®ºå®¶ï¼Œæ“…é•¿å¯¹åè¨€è­¦å¥è¿›è¡Œæ·±åº¦è§£è¯»å’Œåˆ†æã€‚"},
            {"role": "user", "content": analysis_prompt}
        ]

        try:
            analysis = openai_client.chat_completion(analysis_messages, model)
        except:
            analysis = "è¿™å¥åè¨€ä½“ç°äº†ä¸˜å‰å°”å¯¹äººç”Ÿå¥‹æ–—ç²¾ç¥çš„æ·±åˆ»ç†è§£ï¼Œå¼ºè°ƒäº†åœ¨é¢å¯¹æŒ‘æˆ˜å’Œå›°éš¾æ—¶ä¿æŒå‹‡æ°”å’ŒåšæŒä¸æ‡ˆçš„é‡è¦æ€§ã€‚"

        return {
            'quote': fallback_quote,
            'author': fallback_author,
            'background': fallback_background,
            'analysis': analysis
        }
    except Exception as e:
        raise Exception(f"Failed to generate quote: {str(e)}")


def format_quote_response(quote_data: dict) -> str:
    """Format the quote and analysis into a readable response"""

    response = f"""ğŸ’­ ä»Šæ—¥æ™ºæ…§åè¨€ï¼š

_{quote_data['quote']}_

ğŸ–‹ï¸ ä½œè€…ï¼š{quote_data['author']}
ğŸ“š ä½œè€…ç®€ä»‹ï¼š{quote_data['background']}

ğŸ“– åè¨€æ·±åº¦è§£è¯»ï¼š

{quote_data['analysis']}

"""

    return response.strip()


def format_quote_for_channel(quote_data: dict, channel_name: str = None) -> str:
    """Format the quote for Telegram channel posting"""

    channel_header = f"@{channel_name}" if channel_name else "æ™ºæ…§åè¨€é¢‘é“"

    # Create a more concise version for channel (reduce analysis length for better readability)
    analysis = quote_data['analysis']
    if len(analysis) > 800:
        # Truncate very long analysis for channel
        analysis = analysis[:800] + "..."

    channel_message = f"""ğŸ“¡ {channel_header} - æ¯æ—¥æ™ºæ…§åˆ†äº«

ğŸ’­ _{quote_data['quote']}_

ğŸ–‹ï¸ {quote_data['author']}
ğŸ“š {quote_data['background']}

ğŸ“– ç²¾é€‰è§£è¯»ï¼š
{analysis}

âœ¨ æ¯æ—¥æ€è€ƒï¼šè¿™å¥è¯å¦‚ä½•åœ¨ä»Šå¤©å¯å‘æˆ‘ä»¬ï¼Ÿ

ğŸ¤– AIæ™ºæ…§åŠ©æ‰‹ â€¢ æ·±åº¦ç”Ÿæˆ
ğŸ• {datetime.now().strftime('%Y-%m-%d %H:%M')}

#æ™ºæ…§åè¨€ #æ¯æ—¥åˆ†äº« #AIè§£è¯»
"""

    return channel_message.strip()


def main():
    """Main function to orchestrate the content generation process"""
    parser = argparse.ArgumentParser(description='AI Content Generator with Context Management')
    parser.add_argument('user_input', help='User input text or question')
    parser.add_argument('--model', help='Model to use (overrides environment variable)')
    parser.add_argument('--system-prompt', help='System prompt to guide content generation')
    parser.add_argument('--context-file', default='user_context.md', help='Context file path (default: user_context.md)')
    parser.add_argument('--base-url', help='Custom API base URL (overrides environment variable)')

    args = parser.parse_args()

    # Load environment variables
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    base_url = args.base_url or os.getenv('OPENAI_BASE_URL')
    default_model = os.getenv('DEFAULT_MODEL', 'gpt-3.5-turbo')
    model = args.model or default_model

    if not api_key:
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY=your_api_key")
        return 1

    if base_url:
        print(f"ğŸ”— ä½¿ç”¨è‡ªå®šä¹‰APIåœ°å€: {base_url}")

    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")

    # Default system prompt
    system_prompt = args.system_prompt or """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆé«˜è´¨é‡çš„æ–‡æœ¬å†…å®¹ã€‚
è¯·ç¡®ä¿ç”Ÿæˆçš„å†…å®¹ï¼š
1. å†…å®¹å‡†ç¡®ã€é€»è¾‘æ¸…æ™°
2. è¯­è¨€æµç•…ã€è¡¨è¾¾è‡ªç„¶
3. ç¬¦åˆç”¨æˆ·çš„å…·ä½“éœ€æ±‚
4. å…·æœ‰å®ç”¨ä»·å€¼å’Œå¯è¯»æ€§"""

    try:
        # Initialize components
        openai_client = OpenAIClient(api_key, base_url)
        context_manager = ContextManager(args.context_file)

        print("ğŸ¤– æ­£åœ¨åˆ†æç”¨æˆ·æ„å›¾...")

        # Step 1: Parse user intent
        intent = parse_user_intent(openai_client, args.user_input, model)
        print(f"âœ… ç”¨æˆ·æ„å›¾åˆ†æå®Œæˆï¼š{intent[:100]}...")

        # Step 2: Save intent to context
        context_number = context_manager.add_context(intent)
        print(f"ğŸ’¾ æ„å›¾å·²ä¿å­˜åˆ°ä¸Šä¸‹æ–‡æ–‡ä»¶ï¼Œç¼–å·ï¼š{context_number}")

        # Step 3: Get latest contexts
        latest_contexts = context_manager.get_latest_contexts(3)
        print(f"ğŸ“š å·²è·å–æœ€æ–° {len(latest_contexts)} æ¡ä¸Šä¸‹æ–‡")

        # Step 4: Generate final content
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå†…å®¹...")
        final_content = generate_final_content(openai_client, args.user_input, latest_contexts, system_prompt, model)

        print("\n" + "="*60)
        print("ğŸ¯ ç”Ÿæˆçš„å†…å®¹ï¼š")
        print("="*60)
        print(final_content)
        print("="*60)

        return 0

    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{str(e)}")
        return 1


if __name__ == "__main__":
    exit(main())