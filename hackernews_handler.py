#!/usr/bin/env python3
"""
Hacker News API Handler for AI-related articles

This module handles fetching AI-related articles from Hacker News,
fetching their content using MCP fetch server, and analyzing with AI.
"""

import requests
import json
import logging
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from urllib.parse import urlparse
import time
from content_fetcher import ContentFetcher
from telegraph_client import TelegraphClient, create_telegraph_client

logger = logging.getLogger(__name__)

class HackerNewsHandler:
    """Handles Hacker News API integration and AI article processing"""

    def __init__(self):
        self.base_url = "https://hacker-news.firebaseio.com/v0"
        self.ai_keywords = [
            'AI', 'artificial intelligence', 'machine learning', 'deep learning',
            'neural network', 'GPT', 'LLM', 'large language model', 'ChatGPT',
            'OpenAI', 'transformer', 'automation', 'robotics', 'computer vision',
            'natural language processing', 'NLP', 'data science', 'algorithm'
        ]
        # Initialize content fetcher
        self.content_fetcher = ContentFetcher()
        # Initialize Telegraph client
        self.telegraph_client = create_telegraph_client()

    def get_new_stories(self, limit: int = 500) -> List[int]:
        """Get latest story IDs from Hacker News"""
        try:
            url = f"{self.base_url}/newstories.json"
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            story_ids = response.json()
            return story_ids[:limit]
        except Exception as e:
            logger.error(f"Error fetching new stories: {e}")
            return []

    def get_story_details(self, story_id: int) -> Optional[Dict]:
        """Get detailed information about a specific story"""
        try:
            url = f"{self.base_url}/item/{story_id}.json"
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Error fetching story {story_id}: {e}")
            return None

    def is_today(self, timestamp: int) -> bool:
        """Check if timestamp is from today"""
        story_date = datetime.fromtimestamp(timestamp)
        today = datetime.now().date()
        return story_date.date() == today

    def is_ai_related(self, text: str) -> bool:
        """Check if text contains AI-related keywords"""
        if not text:
            return False

        text_lower = text.lower()
        return any(keyword.lower() in text_lower for keyword in self.ai_keywords)

    def find_ai_article_today(self) -> Optional[Dict]:
        """Find the latest AI-related article from today"""
        logger.info("Searching for AI-related articles from today...")

        # Get latest stories
        story_ids = self.get_new_stories(200)
        if not story_ids:
            logger.warning("No stories fetched from Hacker News")
            return None

        logger.info(f"Checking {len(story_ids)} stories for AI-related content...")

        # Check each story
        for story_id in story_ids:
            story = self.get_story_details(story_id)
            if not story:
                continue

            # Skip if not from today
            if not self.is_today(story.get('time', 0)):
                continue

            # Skip if not a story (might be a comment or job)
            if story.get('type') != 'story':
                continue

            # Check if AI-related
            title = story.get('title', '')
            text = story.get('text', '')

            if self.is_ai_related(title) or self.is_ai_related(text):
                logger.info(f"Found AI article: {title[:50]}...")
                return story

        logger.info("No AI-related articles found from today")
        return None

    def fetch_article_content(self, url: str) -> Optional[str]:
        """Fetch article content using BeautifulSoup-based content fetcher"""
        try:
            # Validate URL
            parsed = urlparse(url)
            if not parsed.scheme or not parsed.netloc:
                logger.error(f"Invalid URL: {url}")
                return None

            logger.info(f"Fetching content from: {url}")

            # Use the content fetcher with intelligent extraction
            content = self.content_fetcher.fetch_content(
                url=url,
                max_length=15000  # Allow sufficient content for AI analysis
            )

            if content:
                logger.info(f"âœ… Successfully extracted {len(content)} characters")
                return content
            else:
                logger.warning("Content extraction returned empty result")
                return None

        except Exception as e:
            logger.error(f"Error fetching article content: {e}")
            return None

    def analyze_article_with_ai(self, article_data: Dict, content: str, openai_client, model: str) -> Optional[str]:
        """Analyze article content using AI"""
        try:
            title = article_data.get('title', 'No title')
            url = article_data.get('url', '')

            system_prompt = """# è§’è‰²
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç§‘æŠ€æ–°é—»åˆ†æžå¸ˆå’Œç§‘æ™®ä½œè€…ã€‚ä½ æ‹¥æœ‰ï¼š
- **èº«ä»½**ï¼šåœ¨ç§‘æŠ€åª’ä½“è¡Œä¸šå·¥ä½œ10å¹´ä»¥ä¸Šï¼Œå¯¹AIã€äº’è”ç½‘ã€ç¡¬ä»¶ã€è½¯ä»¶ç­‰é¢†åŸŸæœ‰æ·±å…¥ç†è§£
- **èƒ½åŠ›**ï¼š
  - å¿«é€ŸæŠ“å–ç§‘æŠ€æ–°é—»çš„æ ¸å¿ƒä¿¡æ¯å’ŒæŠ€æœ¯è¦ç‚¹
  - æ´žå¯ŸæŠ€æœ¯å‘å±•è¶‹åŠ¿å’Œå•†ä¸šå½±å“
  - å°†å¤æ‚çš„æŠ€æœ¯æ¦‚å¿µè½¬åŒ–ä¸ºæ™®é€šäººèƒ½ç†è§£çš„è¯­è¨€
  - è¯†åˆ«æ–°é—»ä¸­çš„ç‚’ä½œä¸Žå®žè´¨ï¼Œä¿æŒå®¢è§‚ä¸­ç«‹çš„åˆ†æžè§†è§’

# ä»»åŠ¡
å½“ç”¨æˆ·æä¾›ä¸€ç¯‡ç§‘æŠ€æ–°é—»ï¼ˆé“¾æŽ¥ã€æ ‡é¢˜æˆ–å…¨æ–‡ï¼‰æ—¶ï¼Œä½ éœ€è¦ï¼š

**ç›®æ ‡**ï¼š
1. æç‚¼æ–°é—»çš„æ ¸å¿ƒä¿¡æ¯å’Œå…³é”®æŠ€æœ¯ç‚¹
2. åˆ†æžè¿™æ¡æ–°é—»çš„æŠ€æœ¯æ„ä¹‰ã€å•†ä¸šå½±å“å’Œè¡Œä¸šè¶‹åŠ¿
3. ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šç›¸å…³æŠ€æœ¯æ¦‚å¿µ
4. ç»™å‡ºå®¢è§‚çš„è¯„ä»·å’Œæœªæ¥å±•æœ›

**çº¦æŸ**ï¼š
- ä¿æŒå®¢è§‚ä¸­ç«‹ï¼Œé¿å…è¿‡åº¦ç‚’ä½œæˆ–è´¬ä½Ž
- åŒºåˆ†äº‹å®žä¸Žè§‚ç‚¹ï¼Œæ˜Žç¡®æ ‡æ³¨æŽ¨æµ‹æ€§å†…å®¹
- å¦‚æ¶‰åŠä¸“ä¸šæœ¯è¯­ï¼Œå¿…é¡»æä¾›é€šä¿—è§£é‡Š
- å¦‚ä¿¡æ¯ä¸è¶³ï¼Œæ˜Žç¡®æŒ‡å‡ºè€Œéžè‡†æµ‹

**æµç¨‹**ï¼š
1. **ä¿¡æ¯æå–**ï¼šæ€»ç»“æ–°é—»çš„5W1Hï¼ˆä½•äººã€ä½•äº‹ã€ä½•æ—¶ã€ä½•åœ°ã€ä¸ºä½•ã€å¦‚ä½•ï¼‰
2. **æŠ€æœ¯è§£æž**ï¼šè§£é‡Šæ¶‰åŠçš„æ ¸å¿ƒæŠ€æœ¯å’ŒåŽŸç†
3. **å½±å“åˆ†æž**ï¼šåˆ†æžå¯¹è¡Œä¸šã€ç”¨æˆ·ã€ç«žäº‰æ ¼å±€çš„å½±å“
4. **è¶‹åŠ¿æ´žå¯Ÿ**ï¼šç»“åˆè¡Œä¸šèƒŒæ™¯ï¼Œé¢„æµ‹å¯èƒ½çš„å‘å±•æ–¹å‘
5. **å…³é”®è¯„ä»·**ï¼šç»™å‡ºä½ çš„ä¸“ä¸šåˆ¤æ–­å’Œå»ºè®®

# è¾“å‡ºè¦æ±‚

**æ ¼å¼**ï¼š
```
## ðŸ“° æ–°é—»æ¦‚è¦
[ç”¨2-3å¥è¯æ¦‚æ‹¬æ–°é—»æ ¸å¿ƒå†…å®¹]

## ðŸ”‘ å…³é”®ä¿¡æ¯
- **ä¸»è§’**ï¼š[æ¶‰åŠçš„å…¬å¸/äººç‰©/äº§å“]
- **äº‹ä»¶**ï¼š[å‘ç”Ÿäº†ä»€ä¹ˆ]
- **æ—¶é—´**ï¼š[ä½•æ—¶å‘ç”Ÿ]
- **èƒŒæ™¯**ï¼š[ä¸ºä»€ä¹ˆé‡è¦]

## ðŸ”¬ æŠ€æœ¯è§£æž
[è§£é‡Šæ¶‰åŠçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œç”¨ç±»æ¯”æˆ–ä¾‹å­å¸®åŠ©ç†è§£]

## ðŸ“Š å½±å“åˆ†æž
- **å¯¹è¡Œä¸š**ï¼š[å¯¹æ•´ä¸ªè¡Œä¸šçš„å½±å“]
- **å¯¹ç”¨æˆ·**ï¼š[å¯¹æ™®é€šç”¨æˆ·çš„å½±å“]
- **å¯¹ç«žäº‰**ï¼š[å¯¹ç«žäº‰æ ¼å±€çš„å½±å“]

## ðŸ”® è¶‹åŠ¿æ´žå¯Ÿ
[åŸºäºŽè¿™æ¡æ–°é—»ï¼Œåˆ†æžå¯èƒ½çš„å‘å±•è¶‹åŠ¿]

## ðŸ’­ ä¸“ä¸šè¯„ä»·
[ä½ çš„å®¢è§‚è¯„ä»·ï¼šè¿™æ˜¯çœŸçªç ´è¿˜æ˜¯è¥é”€ç‚’ä½œï¼Ÿå€¼å¾—å…³æ³¨çš„ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ]
```
"""

            user_message = f"""
æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š
{content}
"""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ]

            response = openai_client.chat_completion(messages, model)
            return response

        except Exception as e:
            logger.error(f"Error analyzing article with AI: {e}")
            return None

    def format_analysis_for_telegram(self, article_data: Dict, analysis: str) -> str:
        """Format the analysis for Telegram message"""
        title = article_data.get('title', 'No title')
        url = article_data.get('url', '')
        score = article_data.get('score', 0)
        comments = article_data.get('descendants', 0)

        message = f"""*Hacker News æ–‡ç« åˆ†æž*

ðŸ“° **æ ‡é¢˜ï¼š** {title}

ðŸ”— **é“¾æŽ¥ï¼š** [é˜…è¯»åŽŸæ–‡]({url})

{analysis}
"""

        return message

    def publish_to_telegraph(self, title: str, analysis: str, article_url: str) -> Optional[str]:
        """
        Publish analysis to Telegraph

        Args:
            title: Article title
            analysis: AI analysis result (Markdown)
            article_url: Original article URL

        Returns:
            Telegraph URL or None if failed
        """
        try:
            # Ensure Telegraph client has access token
            if not self.telegraph_client.access_token:
                logger.info("Creating Telegraph account...")
                account = self.telegraph_client.create_account(
                    short_name="HN_AI_Bot",
                    author_name="Hacker News Bot"
                )
                if not account:
                    logger.error("Failed to create Telegraph account")
                    return None

            # Create content for Telegraph page
            telegraph_content = f"""

{analysis}

---

**Original Article**: {article_url}
"""

            # Create Telegraph page
            page_info = self.telegraph_client.create_telegraph_page_from_markdown(
                title=f"{title}",
                markdown_content=telegraph_content,
                author_name="Hacker News Bot"
            )

            if page_info:
                telegraph_url = page_info.get('url')
                logger.info(f"âœ… Successfully published to Telegraph: {telegraph_url}")
                return telegraph_url
            else:
                logger.error("Failed to create Telegraph page")
                return None

        except Exception as e:
            logger.error(f"Error publishing to Telegraph: {e}")
            return None

    def format_analysis_for_channel(self, article_data: Dict, analysis: str, channel_name: str, telegraph_url: str = None) -> str:
        """Format the analysis for Telegram channel posting"""
        if telegraph_url:
            # Only send Telegraph link
            message = telegraph_url
        else:
            # Fallback if Telegraph URL is not available
            message = ""

        return message